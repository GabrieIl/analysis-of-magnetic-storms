{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from calendar import monthrange\n",
    "from typing import Union, List, Dict\n",
    "from libraries.IndexesExtraction import IndexesExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [str(i) for i in list(range(1964, 2022))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_rules = {\n",
    "    'fraca':            np.array(range(-31, -51, -1)),\n",
    "    'moderada':         np.array(range(-51, -101, -1)),\n",
    "    'intensa':          np.array(range(-101, -251, -1)),\n",
    "    'super_intensa':    np.array(range(-251, -1001, -1)),\n",
    "}\n",
    "\n",
    "# indexes = IndexesExtraction(periods=periods)\n",
    "# indexes.make_classification(classification_rules, classification_by_column='Dst_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/gabriel/tcc/OMNI/processed_data/{name}.h5\n",
    "#F:/Meus_Documentos/Documentos/GitHub/analysis-of-magnetic-storms/OMNI/processed_data/full_data.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(df, folder_name: str, name: str):\n",
    "    processed_data = pd.HDFStore(path=f'F:/Meus_Documentos/Documentos/GitHub/analysis-of-magnetic-storms/OMNI/processed_data/full_data.h5')\n",
    "    processed_data.append('df', df)\n",
    "    processed_data.close()\n",
    "    print(f'Seus dados foram salvos em: processed_data/{name}.h5\\n')\n",
    "\n",
    "\n",
    " #save_processed_data(df=df_test, folder_name='OMNI', name='full_data')\n",
    "\n",
    "def load_processed_data(folder_name:str, name: str):\n",
    "    processed_data = pd.HDFStore(path=f'F:/Meus_Documentos/Documentos/GitHub/analysis-of-magnetic-storms/OMNI/processed_data/full_data.h5')\n",
    "    df = processed_data['df']\n",
    "    processed_data.close()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = load_processed_data(folder_name='OMNI', name='full_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Dst_index</th>\n",
       "      <th>Kp_index</th>\n",
       "      <th>B_scalar</th>\n",
       "      <th>Bz_GSM</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-06-07</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>fraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2001-06-12</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>moderada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2001-06-18</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>fraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2001-06-27</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>fraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1986-12-12</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>999.9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>fraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21176</th>\n",
       "      <td>1996-09-22</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>fraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21177</th>\n",
       "      <td>1996-09-23</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>fraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21180</th>\n",
       "      <td>1996-09-26</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>fraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21183</th>\n",
       "      <td>1996-09-29</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>fraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21184</th>\n",
       "      <td>1996-09-30</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>fraca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6967 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  Dst_index  Kp_index  B_scalar  Bz_GSM classification\n",
       "6     2001-06-07      -36.0      57.0      12.5    -6.1          fraca\n",
       "11    2001-06-12      -61.0      53.0      19.3   -11.8       moderada\n",
       "17    2001-06-18      -33.0      57.0       8.4    -4.1          fraca\n",
       "26    2001-06-27      -46.0      37.0      16.3    -7.1          fraca\n",
       "41    1986-12-12      -39.0      43.0     999.9   999.9          fraca\n",
       "...          ...        ...       ...       ...     ...            ...\n",
       "21176 1996-09-22      -37.0      27.0       7.5    -3.2          fraca\n",
       "21177 1996-09-23      -42.0      50.0      12.2    -7.5          fraca\n",
       "21180 1996-09-26      -38.0      50.0       9.3    -5.7          fraca\n",
       "21183 1996-09-29      -42.0      43.0       9.7    -4.8          fraca\n",
       "21184 1996-09-30      -41.0      40.0       7.1    -4.6          fraca\n",
       "\n",
       "[6967 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(df_test[df_test['Dst_index'] == 999.9].index, inplace=True)\n",
    "df_test.drop(df_test[df_test['B_scalar'] == 999.9].index, inplace=True)\n",
    "df_test.drop(df_test[df_test['Bz_GSM'] == 999.9].index, inplace=True)\n",
    "df_test.drop(df_test[df_test['Dst_index'] == 999.9].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_count(df):\n",
    "    count = {\"fraca\": 0, \"moderada\": 0, \"intensa\": 0, \"super_intensa\": 0}\n",
    "    for i in range(1, len(df)):\n",
    "        count[df['classification'].iloc[i]]+=1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fraca': 2241, 'moderada': 1105, 'intensa': 216, 'super_intensa': 15}\n"
     ]
    }
   ],
   "source": [
    "class_count(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_train, y_test, y_pred, partition: str):\n",
    "    #Relatório de Classificação -> Desempenho por classes | Modelo Final (Usando a partição de avaliação do dataset)\n",
    "\n",
    "    if partition == 'tr':\n",
    "        print(\"\\nRelatório de Classificação do modelo final:\\n\\n\", classification_report(y_train, y_pred, digits=4))\n",
    "        matrix = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "    if partition == 'te':\n",
    "        print(\"\\nRelatório de Classificação do modelo final:\\n\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "        matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "\n",
    "    #Matriz de confusão\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(matrix, annot=True, ax=ax, fmt='d', cmap='Reds')\n",
    "\n",
    "    ax.set_title(\"Matriz de Confusão\", fontsize=18)\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    ax.set_xlabel(\"Predicted Label\")\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_range(results):\n",
    "    mean = results.mean()\n",
    "    dv = results.std()\n",
    "    print('Acurácia média: {:.2f}%'.format(mean*100))\n",
    "    print('Intervalo de acurácia: [{:.2f}% ~ {:.2f}%]'.format((mean - 2*dv)*100, (mean + 2*dv)*100))\n",
    "    print(results)\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_range(results):\n",
    "  mean = results.mean()\n",
    "  dv = results.std()\n",
    "  print('Precisão média: {:.2f}%'.format(mean*100))\n",
    "  print('Intervalo de precisão: [{:.2f}% ~ {:.2f}%]'.format((mean - 2*dv)*100, (mean + 2*dv)*100))\n",
    "  print(results)\n",
    "  print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_range(results):\n",
    "  mean = results.mean()\n",
    "  dv = results.std()\n",
    "  print('Recall médio: {:.2f}%'.format(mean*100))\n",
    "  print('Intervalo de recall: [{:.2f}% ~ {:.2f}%]'.format((mean - 2*dv)*100, (mean + 2*dv)*100))\n",
    "  print(results)\n",
    "  print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.base, sklearn.model_selection\n",
    "def cros_val_scoring(model: sklearn.base.BaseEstimator, x: any, y:any, cv: int | sklearn.model_selection.BaseCrossValidator | sklearn.model_selection.BaseShuffleSplit | None):\n",
    "    accuracy = cross_val_score(model, x, y, cv = cv, scoring='accuracy')\n",
    "    precision = cross_val_score(model, x, y, cv = cv, scoring='precision_macro')\n",
    "    recall = cross_val_score(model, x, y, cv = cv, scoring='recall_macro')\n",
    "\n",
    "    accuracy_range(accuracy)\n",
    "    precision_range(precision)\n",
    "    recall_range(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO BZ -> Dst class\n",
    "\n",
    "def bz_model():\n",
    "\n",
    "    #Codificação da classe alvo\n",
    "    le = LabelEncoder()\n",
    "    df_test['classification'] = le.fit_transform(df_test['classification'])\n",
    "\n",
    "    X = df_test['B_scalar'].values.reshape(-1, 1) \n",
    "    y = df_test['classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "\n",
    "    print('O dataset de treino possui {} tempestades e o de teste {} tempestades.'.format(X_train.shape[0], X_test.shape[0]))\n",
    "    print('--------------------------------------------------------------')\n",
    "\n",
    "    #Definições de modelo e método de validação cruzada\n",
    "    SEED = 10\n",
    "    np.random.seed(SEED)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Scoring médio dos modelos treinados na validação cruzada\n",
    "    cros_val_scoring(model, X_train, y_train, cv)  \n",
    "\n",
    "    \n",
    "    #Relatório de classificação -> Desempenho por classes | Modelo em treinamento (Partição de treino do dataset)\n",
    "    #y_pred = cross_val_predict(model, X_train, y_train, cv = cv)\n",
    "    \n",
    "    #Relatório de Classificação -> Desempenho por classes | Modelo Final (Usando a partição de avaliação do dataset)\n",
    "    np.random.seed(SEED)\n",
    "    final_model = GaussianNB()\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_prob = final_model.predict_proba(X_test)\n",
    "\n",
    "    model_evaluation(y_train, y_test, y_pred, 'te') # 'tr' para treino e 'te' para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO DST-MIN_BZ -> Dst class\n",
    "\n",
    "def dstMin_bz_model():\n",
    "\n",
    "    #Codificação da classe alvo\n",
    "    le = LabelEncoder()\n",
    "    df_test['classification'] = le.fit_transform(df_test['classification'])\n",
    "\n",
    "    X = df_test[['Dst_index','B_scalar']].copy()\n",
    "    y = df_test['classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "\n",
    "    print('O dataset de treino possui {} tempestades e o de teste {} tempestades.'.format(X_train.shape[0], X_test.shape[0]))\n",
    "    print('--------------------------------------------------------------')\n",
    "\n",
    "    #Definições de modelo e método de validação cruzada\n",
    "    SEED = 10\n",
    "    np.random.seed(SEED)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Scoring médio dos modelos treinados na validação cruzada\n",
    "    cros_val_scoring(model, X_train, y_train, cv)  \n",
    "\n",
    "    \n",
    "    #Relatório de classificação -> Desempenho por classes | Modelo em treinamento (Partição de treino do dataset)\n",
    "    #y_pred = cross_val_predict(model, X_train, y_train, cv = cv)\n",
    "    \n",
    "    #Relatório de Classificação -> Desempenho por classes | Modelo Final (Usando a partição de avaliação do dataset)\n",
    "    np.random.seed(SEED)\n",
    "    final_model = GaussianNB()\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_prob = final_model.predict_proba(X_test)\n",
    "\n",
    "    model_evaluation(y_train, y_test, y_pred, 'te') # 'tr' para treino e 'te' para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO DST-MIN_KP-MAX_BZ -> Dst class\n",
    "\n",
    "def dstMin_kpMax_bz_model():\n",
    "\n",
    "    #Codificação da classe alvo\n",
    "    le = LabelEncoder()\n",
    "    df_test['classification'] = le.fit_transform(df_test['classification'])\n",
    "\n",
    "    X = df_test[['Dst_index','Kp_index','B_scalar']].copy()\n",
    "    y = df_test['classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "\n",
    "    print('O dataset de treino possui {} tempestades e o de teste {} tempestades.'.format(X_train.shape[0], X_test.shape[0]))\n",
    "    print('--------------------------------------------------------------')\n",
    "\n",
    "    #Definições de modelo e método de validação cruzada\n",
    "    SEED = 10\n",
    "    np.random.seed(SEED)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Scoring médio dos modelos treinados na validação cruzada\n",
    "    cros_val_scoring(model, X_train, y_train, cv)  \n",
    "\n",
    "    \n",
    "    #Relatório de classificação -> Desempenho por classes | Modelo em treinamento (Partição de treino do dataset)\n",
    "    #y_pred = cross_val_predict(model, X_train, y_train, cv = cv)\n",
    "    \n",
    "    #Relatório de Classificação -> Desempenho por classes | Modelo Final (Usando a partição de avaliação do dataset)\n",
    "    np.random.seed(SEED)\n",
    "    final_model = GaussianNB()\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_prob = final_model.predict_proba(X_test)\n",
    "\n",
    "    model_evaluation(y_train, y_test, y_pred, 'te') # 'tr' para treino e 'te' para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO DST-MIN -> Dst class\n",
    "def dstMin_model():\n",
    "    #Codificação da classe alvo\n",
    "    le = LabelEncoder()\n",
    "    df_test['classification'] = le.fit_transform(df_test['classification'])\n",
    "\n",
    "    # Divisao entre treino/teste e avaliação do dataframe original\n",
    "    X = df_test['Dst_index'].values.reshape(-1, 1) \n",
    "    y = df_test['classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "\n",
    "    print('O dataset de treino possui {} tempestades e o de teste {} tempestades.'.format(X_train.shape[0], X_test.shape[0]))\n",
    "    print('--------------------------------------------------------------')\n",
    "\n",
    "    #Definições de modelo e método de validação cruzada\n",
    "    SEED = 10\n",
    "    np.random.seed(SEED)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Scoring médio dos modelos treinados na validação cruzada\n",
    "    cros_val_scoring(model, X_train, y_train, cv)  \n",
    "\n",
    "    \n",
    "    #Relatório de classificação -> Desempenho por classes | Modelo em treinamento (Partição de treino do dataset)\n",
    "    #y_pred = cross_val_predict(model, X_train, y_train, cv = cv)\n",
    "    \n",
    "    #Relatório de Classificação -> Desempenho por classes | Modelo Final (Usando a partição de avaliação do dataset)\n",
    "    np.random.seed(SEED)\n",
    "    final_model = GaussianNB()\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_prob = final_model.predict_proba(X_test)\n",
    "\n",
    "    model_evaluation(y_train, y_test, y_pred, 'te') # 'tr' para treino e 'te' para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO KP -> Dst class\n",
    "def kp_model():\n",
    "    #Codificação da classe alvo\n",
    "    le = LabelEncoder()\n",
    "    df_test['classification'] = le.fit_transform(df_test['classification'])\n",
    "\n",
    "    # Divisao entre treino/teste e avaliação do dataframe original\n",
    "    X = df_test['Kp_index'].values.reshape(-1, 1) \n",
    "    y = df_test['classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "\n",
    "    print('O dataset de treino possui {} tempestades e o de teste {} tempestades.'.format(X_train.shape[0], X_test.shape[0]))\n",
    "    print('--------------------------------------------------------------')\n",
    "\n",
    "    #Definições de modelo e método de validação cruzada\n",
    "    SEED = 10\n",
    "    np.random.seed(SEED)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Scoring médio dos modelos treinados na validação cruzada\n",
    "    cros_val_scoring(model, X_train, y_train, cv)  \n",
    "\n",
    "    \n",
    "    #Relatório de classificação -> Desempenho por classes | Modelo em treinamento (Partição de treino do dataset)\n",
    "    #y_pred = cross_val_predict(model, X_train, y_train, cv = cv)\n",
    "    \n",
    "    #Relatório de Classificação -> Desempenho por classes | Modelo Final (Usando a partição de avaliação do dataset)\n",
    "    np.random.seed(SEED)\n",
    "    final_model = GaussianNB()\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_prob = final_model.predict_proba(X_test)\n",
    "\n",
    "    model_evaluation(y_train, y_test, y_pred, 'te') # 'tr' para treino e 'te' para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELO DST-MIN_KP -> Dst class\n",
    "def dstMin_kp_model():\n",
    "    #Codificação da classe alvo\n",
    "    le = LabelEncoder()\n",
    "    df_test['classification'] = le.fit_transform(df_test['classification'])\n",
    "\n",
    "    # Divisao entre treino/teste e avaliação do dataframe original\n",
    "    X = df_test[['Dst_index','Kp_index']].copy()\n",
    "    y = df_test['classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "\n",
    "    print('O dataset de treino possui {} tempestades e o de teste {} tempestades.'.format(X_train.shape[0], X_test.shape[0]))\n",
    "    print('--------------------------------------------------------------')\n",
    "\n",
    "    #Definições de modelo e método de validação cruzada\n",
    "    SEED = 10\n",
    "    np.random.seed(SEED)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    model = GaussianNB()\n",
    "\n",
    "    #Scoring médio dos modelos treinados na validação cruzada\n",
    "    cros_val_scoring(model, X_train, y_train, cv)  \n",
    "\n",
    "    \n",
    "    #Relatório de classificação -> Desempenho por classes | Modelo em treinamento (Partição de treino do dataset)\n",
    "    #y_pred = cross_val_predict(model, X_train, y_train, cv = cv)\n",
    "    \n",
    "    #Relatório de Classificação -> Desempenho por classes | Modelo Final (Usando a partição de avaliação do dataset)\n",
    "    np.random.seed(SEED)\n",
    "    final_model = GaussianNB()\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_prob = final_model.predict_proba(X_test)\n",
    "\n",
    "    model_evaluation(y_train, y_test, y_pred, 'te') # 'tr' para treino e 'te' para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dstMin_model()\n",
    "#bz_model()\n",
    "#kp_model()\n",
    "#dstMin_bz_model()\n",
    "#dstMin_kp_model()\n",
    "#dstMin_kpMax_bz_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
