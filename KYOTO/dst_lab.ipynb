{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from typing import List, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL_DST_FINAL = 'https://wdc.kugi.kyoto-u.ac.jp/dst_final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_data(year: str, month: str) -> Union[str, Exception]:\n",
    "    \"\"\"\n",
    "    year [str]: YYYYY\n",
    "    month [str]: DD\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL_DST_FINAL}/{year}{month}/index.html\"\n",
    "    try:\n",
    "        ans = requests.get(url=url)\n",
    "        data = soup(ans.text, \"html.parser\")\n",
    "        text_from_html = data.findAll(\"pre\")[0].text\n",
    "        return text_from_html\n",
    "    except Exception as error:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_data_text(data_text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    data_text [str]\n",
    "    \"\"\"\n",
    "    raw_data = list()\n",
    "    _ = [raw_data.append(i) for i in data_text.split('\\n') if i != '']\n",
    "    return raw_data[6:]\n",
    "\n",
    "\n",
    "def clean_single_line(line: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    line [str]\n",
    "    \"\"\"\n",
    "    # seleciona somente os valores de dst dentro da lista\n",
    "    # quebra o texto em 3 blocos com 33 caracteres\n",
    "    split_three_blocks = re.findall('.................................', line[2:])\n",
    "    # remove o primeiro caracter de cada bloco\n",
    "    clean_blocks = list()\n",
    "    _ = [clean_blocks.append(i[1:]) for i in split_three_blocks]\n",
    "    # separa os blocos em conjuntos de 4 caracteres\n",
    "    # converte valores de string para inteiro\n",
    "    separated_values = [int(i) for i in re.findall('....', ''.join(clean_blocks))]\n",
    "    return separated_values\n",
    "\n",
    "\n",
    "def clean_multiples_lines(lines: List[str]):\n",
    "    lines_ok = list()\n",
    "    _ = [lines_ok.append(clean_single_line(i)) for i in lines]\n",
    "    return lines_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(trusted_data: List[List[int]], year: str, month: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Corrige data: 24h00 -> 00h00\n",
    "    for i, day_indexex in enumerate(trusted_data):\n",
    "        trusted_data[i].insert(0, day_indexex.pop())\n",
    "   \n",
    "    df = pd.DataFrame(trusted_data, columns=list(range(0, 24)))\n",
    "    df.index = df.index+1\n",
    "    df['date'] = [pd.to_datetime(f\"{year}-{month}-{day}\", format='%Y-%m-%d') for day in df.index]\n",
    "    df['dst_min'] = [df.loc[i, np.array(range(0, 24))].min() for i in range(1, len(df)+1)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification(df: pd.DataFrame, classification_rules: Dict[str, List[int]]):\n",
    "    \"\"\"\n",
    "    df [DataFrame]\n",
    "    classification_rules [Dict[str, List[int]]]\n",
    "        example:\n",
    "            {\n",
    "                'fraca':            np.array(range(-31, -51, -1)),\n",
    "                'moderada':         np.array(range(-51, -101, -1)),\n",
    "                'intensa':          np.array(range(-101, -251, -1)),\n",
    "                'super_intensa':    np.array(range(-251, -1001, -1)),\n",
    "            }\n",
    "    \"\"\"\n",
    "    df['classification'] = np.nan\n",
    "    for i in range(1, len(df)+1):\n",
    "        for category, index_range in classification_rules.items(): \n",
    "            if df.loc[i, 'dst_min'] in index_range:\n",
    "                df.loc[i, 'classification'] = category\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_storms_by_date(df: pd.DataFrame, dates: List[str]):\n",
    "    \"\"\"\n",
    "    df: DataFrame\n",
    "        columns: \n",
    "            date pd.datetime\n",
    "    dates: list[str]\n",
    "        format: YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    format_dates = [pd.to_datetime(date, format='%Y-%m-%d') for date in dates]\n",
    "    boolean_mask = [date not in format_dates for date in df['date']]\n",
    "    final_mask = pd.Series(boolean_mask, name='date', index=list(range(1, len(df)+1)))\n",
    "    filtered_df = df[final_mask]\n",
    "    filtered_df.reset_index(drop=True, inplace=True)\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(df, year, month):\n",
    "    processed_data = pd.HDFStore(path=f'processed_data/{year}{month}.h5')\n",
    "    processed_data.append('df', df)\n",
    "    processed_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dst_graph(df):\n",
    "    # alta resolução\n",
    "    axis_x = [(i+1)/df.columns.size for i in range(df.columns.size*len(df))]\n",
    "\n",
    "    elements = [df.iloc[i].to_list() for i in range(len(df))]\n",
    "    axis_y = list()\n",
    "    for element in elements:\n",
    "        axis_y += element\n",
    "\n",
    "    plt.plot(axis_x, axis_y)\n",
    "\n",
    "    # baixa resolução\n",
    "    # df.min(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = \\\n",
    "\"\"\"\n",
    "[Fraca]          -30 nT > Dst >=  -50 nT\n",
    "[Moderada]       -50 nT > Dst >= -100 nT\n",
    "[Intensa]       -100 nT > Dst >= -250 nT\n",
    "[SuperIntensa]  -250 nT > Dst \n",
    "\"\"\"\n",
    "\n",
    "classification_rules = {\n",
    "    'fraca':            np.array(range(-31, -51, -1)),\n",
    "    'moderada':         np.array(range(-51, -101, -1)),\n",
    "    'intensa':          np.array(range(-101, -251, -1)),\n",
    "    'super_intensa':    np.array(range(-251, -1001, -1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2003'\n",
    "month = '11'\n",
    "\n",
    "month_data = get_month_data(year=year, month=month)\n",
    "cleaned_data = clean_month_data_text(data_text=month_data)\n",
    "trusted_data = clean_multiples_lines(lines=cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_df(trusted_data=trusted_data, year=year, month=month)\n",
    "make_classification(df, classification_rules)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storms_to_remove_by_date = [\n",
    "    '2000-07-01',\n",
    "    '2000-07-02',\n",
    "    '2000-07-03',\n",
    "    '2000-07-29',\n",
    "    '2000-07-30'\n",
    "]\n",
    "df_filtered = remove_storms_by_date(df, storms_to_remove_by_date).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_count(df: pd.DataFrame):\n",
    "    count = {\"fraca\": 0, \"moderada\": 0, \"intensa\": 0, \"super_intensa\": 0}\n",
    "    for i in range(1, len(df)):\n",
    "        count[df['classification'].iloc[i]]+=1\n",
    "    print(count)\n",
    "class_count(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_range(results):\n",
    "    mean = results.mean()\n",
    "    dv = results.std()\n",
    "    print('Acurácia média: {:.2f}%'.format(mean*100))\n",
    "    print('Intervalo de acurácia: [{:.2f}% ~ {:.2f}%]'.format((mean - 2*dv)*100, (mean + 2*dv)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervalo_prec(results):\n",
    "  for i in range(1, len(results)):\n",
    "    mean = results.mean()\n",
    "    dv = results.std()\n",
    "    print('Precisão média: {:.2f}%'.format(mean*100))\n",
    "    print('Intervalo de Precisão: [{:.2f}% ~ {:.2f}%]'.format((mean - 2*dv)*100, (mean + 2*dv)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_filtered['classification'] = le.fit_transform(df_filtered['classification'])\n",
    "\n",
    "# divisao entre treino e teste do dataframe original\n",
    "X = df_filtered['dst_min'].values.reshape(-1, 1) \n",
    "y = df_filtered['classification']\n",
    "\n",
    "SEED = 10\n",
    "np.random.seed(SEED)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "print('O dataset de treino possui {} tempestades e o de teste {} tempestades.'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "model = GaussianNB()\n",
    "accuracy = cross_val_score(model, X_train, y_train, cv = cv, scoring='accuracy')\n",
    "#precision = cross_val_score(model, X_train, y_train, cv = cv, scoring='precision')\n",
    "\n",
    "accuracy_range(accuracy)\n",
    "#precision_range(precision)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
